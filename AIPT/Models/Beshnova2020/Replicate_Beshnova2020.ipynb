{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::203378532510:role/service-role/AmazonSageMaker-ExecutionRole-Interns'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/AIPT-0.0.1-py3.6.egg/AIPT/Models/Beshnova2020/CNN.py \n",
      " Last modified: 2020-11-11 02:44:32 UTC\n",
      "current working directory:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/antibody-in-pytorch'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import AIPT.Models.Beshnova2020.CNN\n",
    "import AIPT.Utils.logging\n",
    "import AIPT.Utils.plotting\n",
    "\n",
    "import AIPT.Utils.Dev.dev_utils as dev_utils\n",
    "\n",
    "aipt_path = '/home/ec2-user/SageMaker/antibody-in-pytorch/'\n",
    "aipt_reload = dev_utils.get_aipt_reload_fn(aipt_path)\n",
    "\n",
    "os.chdir(aipt_path)\n",
    "print(\"current working directory:\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarks\t__init__.py  Models\t  Utils\n",
      "entry_point.py\t__main__.py  __pycache__\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "set up paths\n",
    "'''\n",
    "\n",
    "aipt_dir = '/home/ec2-user/SageMaker/antibody-in-pytorch/AIPT' # replace with your own aipt path\n",
    "# print(\"\\t\".join(os.listdir(aipt_dir)))\n",
    "!ls {aipt_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 12\n",
    "toy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# todo: pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from AIPT.Benchmarks.OAS_dataset import OAS_data_loader as oas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seq_dir = os.path.join(aipt_dir, \"Benchmarks/OAS_dataset/data/seq_db\")\n",
    "model_dir = 'AIPT/Models/Beshnova2020'\n",
    "model_dir_abs = os.path.join(aipt_path, model_dir)\n",
    "# %cd {model_dir_abs}\n",
    "index_fn = \"OAS_index_large.txt\"\n",
    "index_path = os.path.join(aipt_path, model_dir, index_fn)\n",
    "full_index_path = os.path.join(aipt_path, 'AIPT', 'Benchmarks', 'OAS_dataset', 'data', 'OAS_meta_info.txt')\n",
    "toy_index_path = os.path.join(model_dir_abs, 'OAS_index_small.txt')\n",
    "input_seq_type = \"CDR3\"\n",
    "output_field = \"BType\"\n",
    "cell_types = [\n",
    "    \"Naive-B-Cells\",\n",
    "    \"Memory-B-Cells\",\n",
    "]  # todo: this is confusing - doesn't refer to \"Species\"\n",
    "\n",
    "def index_filter(row):\n",
    "    return row['BType'] in cell_types and row['Species'] == 'human'\n",
    "\n",
    "index_path_to_read = toy_index_path if toy else full_index_path\n",
    "\n",
    "index_df = pd.read_csv(index_path_to_read, sep='\\t')\n",
    "index_df_filtered = index_df[index_df.apply(index_filter, axis=1)]\n",
    "index_df_filtered.to_csv(index_path, sep='\\t')\n",
    "\n",
    "\n",
    "# train_loader, train_eval_loader, test_eval_loader, seq_len = oas.OAS_data_loader(\n",
    "#     index_path,\n",
    "#     output_field,\n",
    "#     input_seq_type,\n",
    "#     cell_types,\n",
    "#     seq_dir=seq_dir,\n",
    "#     gapped=True,\n",
    "#     pad=False,\n",
    "#     batch_size=SEQ_LENGTH,\n",
    "#     model_name=\"Beshnova2020\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Bonsignori_2016_Hiv_infected_week-264_Bulk_HIV...\n",
       "1      Bonsignori_2016_Hiv_infected_week-264_Bulk_HIV...\n",
       "2      Bonsignori_2016_Hiv_infected_week-323_Bulk_HIV...\n",
       "3      Bonsignori_2016_Hiv_infected_week-323_Bulk_HIV...\n",
       "4      Bonsignori_2016_Hiv_infected_week-323_Bulk_HIV...\n",
       "                             ...                        \n",
       "764    Vander_Heiden_2017_Light_MK04_MK04_Naive_Bcell...\n",
       "765    Vander_Heiden_2017_Light_MK05_MK05_Memory_Bcel...\n",
       "766    Vander_Heiden_2017_Light_MK05_MK05_Naive_Bcell...\n",
       "767    Vander_Heiden_2017_Light_MK08_MK08_Memory_Bcel...\n",
       "768    Vander_Heiden_2017_Light_MK08_MK08_Naive_Bcell...\n",
       "Name: file_name, Length: 769, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "index_df = pd.read_csv(index_path, sep=\"\\t\")\n",
    "\n",
    "file_names = index_df['file_name']\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "download_data = False\n",
    "if download_data:\n",
    "    s3_seq_uri = 's3://gv20interns/OAS_dataset/'\n",
    "    for fn in file_names:\n",
    "        print(fn)\n",
    "        sp.run(['aws', 's3', 'cp', os.path.join(s3_seq_uri, f'{fn}.txt'), seq_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def df_len_fn(row):\n",
    "    try:\n",
    "        return len(row['CDR3_aa'])\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "toy = True\n",
    "toy_rows = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from AIPT.Benchmarks.OAS_dataset import OAS_data_loader\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, TensorDataset\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# train_data = data[['CDR3_aa', 'label']]\n",
    "# seq_encodings = OAS_data_loader.encode_index(data=train_data['CDR3_aa'])\n",
    "# btypes = train_data['label'].values\n",
    "# train_loader = torch.utils.data.DataLoader(list(zip(seq_encodings, btypes)), shuffle=True, batch_size=32)\n",
    "\n",
    "def get_balanced_data_loader(data, batch_size=32):\n",
    "    # useful example: https://discuss.pytorch.org/t/some-problems-with-weightedrandomsampler/23242/20\n",
    "    # Compute samples weight (each sample should get its own weight)\n",
    "    label = torch.Tensor(data['label'].values).type(torch.int8)\n",
    "    class_sample_count = torch.tensor(\n",
    "        [(label == t).sum() for t in torch.unique(label, sorted=True)])\n",
    "    weight = 1. / class_sample_count.float()\n",
    "    samples_weight = torch.tensor([weight[t] for t in label])\n",
    "\n",
    "    # Create sampler, dataset, loader\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    seq_encodings = OAS_data_loader.encode_index(data=data['CDR3_aa'])\n",
    "#     dataset = TensorDataset(torch.Tensor(seq_encodings), label)\n",
    "    btypes = data['label'].values\n",
    "    dataset = list(zip(seq_encodings, btypes))\n",
    "    loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=sampler, drop_last=True)\n",
    "    return loader\n",
    "\n",
    "def get_data_loader(data, batch_size=32, shuffle=True):\n",
    "    seq_encodings = OAS_data_loader.encode_index(data=data['CDR3_aa'])\n",
    "    btypes = data['label'].values\n",
    "    loader = DataLoader(list(zip(seq_encodings, btypes)), shuffle=shuffle, batch_size=batch_size, drop_last=True)\n",
    "    return loader\n",
    "\n",
    "def load_data(index_df, seq_len=SEQ_LENGTH):\n",
    "    data_dfs = []\n",
    "    for index, row in index_df.iterrows():\n",
    "        if toy and index > toy_rows:\n",
    "            break\n",
    "        file_name = row['file_name']\n",
    "        df = pd.read_csv(os.path.join(seq_dir, f'{file_name}.txt'), sep='\\t')\n",
    "        length_df = df.apply(df_len_fn, axis=1)\n",
    "        data_df = df[length_df == seq_len]\n",
    "        data_df['BType'] = row['BType']\n",
    "        data_df = data_df[['CDR3_aa', 'BType']]\n",
    "        data_dfs.append(data_df)\n",
    "\n",
    "    data = pd.concat(data_dfs)\n",
    "    data['label'] = data.apply(lambda row: cell_types.index(row['BType']), axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_train_test_loaders(data, train_size=0.8): \n",
    "    train_data, test_data = train_test_split(data, train_size=train_size)\n",
    "    # train_loader = get_balanced_data_loader(train_data)\n",
    "    train_loader = get_data_loader(train_data)\n",
    "    test_loader = get_data_loader(test_data, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "data = load_data(index_df)\n",
    "train_loader, test_loader = get_train_test_loaders(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDR3_aa</th>\n",
       "      <th>BType</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VRVKWEQEDFDF</td>\n",
       "      <td>Memory-B-Cells</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASGGYSYGLFDY</td>\n",
       "      <td>Memory-B-Cells</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TRDPGWGNPVDY</td>\n",
       "      <td>Memory-B-Cells</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ARRRTWPTPFDY</td>\n",
       "      <td>Memory-B-Cells</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>ARSHSSSWYFDY</td>\n",
       "      <td>Memory-B-Cells</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>ARSGSYAGYFDY</td>\n",
       "      <td>Naive-B-Cells</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>ARDDLEVDYFDY</td>\n",
       "      <td>Naive-B-Cells</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>ARGDSYYYYMDV</td>\n",
       "      <td>Naive-B-Cells</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARVRFGDTAVDY</td>\n",
       "      <td>Naive-B-Cells</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARVRFGDTAVDY</td>\n",
       "      <td>Naive-B-Cells</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2425 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          CDR3_aa           BType  label\n",
       "8    VRVKWEQEDFDF  Memory-B-Cells      1\n",
       "9    ASGGYSYGLFDY  Memory-B-Cells      1\n",
       "25   TRDPGWGNPVDY  Memory-B-Cells      1\n",
       "27   ARRRTWPTPFDY  Memory-B-Cells      1\n",
       "74   ARSHSSSWYFDY  Memory-B-Cells      1\n",
       "..            ...             ...    ...\n",
       "793  ARSGSYAGYFDY   Naive-B-Cells      0\n",
       "797  ARDDLEVDYFDY   Naive-B-Cells      0\n",
       "806  ARGDSYYYYMDV   Naive-B-Cells      0\n",
       "0    ARVRFGDTAVDY   Naive-B-Cells      0\n",
       "2    ARVRFGDTAVDY   Naive-B-Cells      0\n",
       "\n",
       "[2425 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: /home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/AIPT-0.0.1-py3.6.egg/AIPT/Models/Beshnova2020/CNN.py \n",
      " Last modified: 2020-11-11 03:31:51 UTC\n",
      "\n",
      "\n",
      "File: /home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/AIPT-0.0.1-py3.6.egg/AIPT/Models/Beshnova2020/pca_embedding.py \n",
      " Last modified: 2020-11-11 03:31:53 UTC\n"
     ]
    }
   ],
   "source": [
    "aipt_reload(AIPT.Models.Beshnova2020.CNN)\n",
    "aipt_reload(AIPT.Utils.logging)\n",
    "aipt_reload(AIPT.Utils.plotting)\n",
    "from AIPT.Models.Beshnova2020.CNN import CNN\n",
    "import AIPT.Models.Beshnova2020.pca_embedding as pca_embedding\n",
    "from AIPT.Utils.logging import today, current_time\n",
    "from AIPT.Utils.plotting import plot_roc_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG DIR: s3://gv20interns/roger/logs/tensorboard/2020-11-10/plots/22.31.54\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# log_root_dir = '/home/ec2-user/SageMaker/logs/tensorboard'\n",
    "log_root_dir = 's3://gv20interns/roger/logs/tensorboard'\n",
    "run_name = 'plots'\n",
    "timezone = 'EST'\n",
    "\n",
    "# para_dict = {\n",
    "#     'seq_len': SEQ_LENGTH,\n",
    "#     'embedding_dim': 15, # paper uses dim 15 PCA features\n",
    "#     'epoch': 300,\n",
    "#     'classes': cell_types,\n",
    "#     'learning_rate': 10**-3,\n",
    "#     'run_name': run_name,\n",
    "#     'log_dir': os.path.join(log_root_dir, today(tz=timezone), run_name, current_time(tz=timezone)),\n",
    "# }\n",
    "\n",
    "para_dict = {\n",
    "    'seq_len': 12,\n",
    "    'classes': cell_types,\n",
    "    'embedding_dim': 15,  # paper uses dim 15 PCA features\n",
    "    'index_file': 'OAS_index_small.txt',\n",
    "    'batch_size': 100,\n",
    "    'epoch': 1000,\n",
    "    'run_name': run_name,\n",
    "    'work_path': os.path.join(model_dir_abs, 'models'),\n",
    "    # tuned hyperparameters from https://us-east-2.console.aws.amazon.com/sagemaker/home?region=us-east-2#/hyper-tuning-jobs/roger-beshnova2020-t-201103-0809\n",
    "    'learning_rate': 0.000125245489276611,\n",
    "    'dropout_rate': 0.1554058115760688,\n",
    "    'conv1_filter_dim1': 2,\n",
    "    'conv1_n_filters': 17,\n",
    "    'conv2_filter_dim1': 1,\n",
    "    'conv2_n_filters': 16,\n",
    "    'max_pool_filter_dim1': 1,\n",
    "    'fc_hidden_dim': 83,\n",
    "    'log_dir': os.path.join(log_root_dir, today(tz=timezone), run_name, current_time(tz=timezone)),\n",
    "}\n",
    "\n",
    "para_dict['conv1_filter_size'] = (para_dict['embedding_dim'], para_dict['conv1_filter_dim1'])\n",
    "para_dict['conv2_filter_size'] = (1, para_dict['conv2_filter_dim1'])\n",
    "para_dict['max_pool_filter_size'] = (1, para_dict['max_pool_filter_dim1'])\n",
    "\n",
    "def get_pca_model(para_dict):\n",
    "    pca_para_dict = para_dict.copy()\n",
    "    pca_para_dict['model_name'] = 'pca_toy2'\n",
    "    pca_embedding_fn = pca_embedding.embedding_fn(20, pca_para_dict['embedding_dim'])\n",
    "    pca_model = CNN(pca_para_dict, pca_embedding_fn)\n",
    "    return pca_model\n",
    "\n",
    "def get_general_model(para_dict):\n",
    "    general_para_dict = para_dict.copy()\n",
    "    general_para_dict['model_name'] = 'general_toy2'\n",
    "    general_embedding_fn = nn.Embedding(20, general_para_dict['embedding_dim'])\n",
    "    general_model = CNN(general_para_dict, general_embedding_fn)\n",
    "    return general_model\n",
    "\n",
    "pca_model = get_pca_model(para_dict)\n",
    "general_model = get_general_model(para_dict)\n",
    "\n",
    "print('LOG DIR:', para_dict['log_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "\n",
    "start_tensorboard = True\n",
    "\n",
    "if start_tensorboard:\n",
    "    reload_interval = \"15\"  # seconds\n",
    "    tensorboard_proc = sp.Popen(\n",
    "        [\n",
    "            \"tensorboard\",\n",
    "            \"--logdir\",\n",
    "            para_dict[\"log_dir\"],\n",
    "        ],\n",
    "        universal_newlines=True,\n",
    "        stdout=sp.PIPE,\n",
    "        stderr=sp.PIPE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "Found saved model from: Epoch 100\n",
      "\n",
      "==================================================\n",
      "EPOCH 100:\n",
      "\n",
      "TRAIN:\n",
      "Total Loss=0.39 Average Loss=6.45e-05\n",
      "[[  77    2]\n",
      " [   0 1841]]\n",
      "Accuracy = 0.999, MCC = 0.987\n",
      "------------------------------\n",
      "TEST:\n",
      "Total Loss=2.94 Average Loss=1.96e-03\n",
      "[[  6  10]\n",
      " [  2 462]]\n",
      "Accuracy = 0.975, MCC = 0.520\n",
      "------------------------------\n",
      "\n",
      "best_epoch=100; best_test_mcc=0.5197726878069531;\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "EPOCH 110:\n",
      "\n",
      "TRAIN:\n",
      "Total Loss=0.28 Average Loss=4.68e-05\n",
      "[[  77    2]\n",
      " [   0 1841]]\n",
      "Accuracy = 0.999, MCC = 0.987\n",
      "------------------------------\n",
      "TEST:\n",
      "Total Loss=3.14 Average Loss=2.09e-03\n",
      "[[  6  10]\n",
      " [  4 460]]\n",
      "Accuracy = 0.971, MCC = 0.460\n",
      "------------------------------\n",
      "\n",
      "best_epoch=100; best_test_mcc=0.5197726878069531;\n",
      "==================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-8955fa4298b7>\", line 2, in <module>\n",
      "    pca_model.fit(train_loader, test_loader=test_loader)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/AIPT-0.0.1-py3.6.egg/AIPT/Models/Beshnova2020/CNN.py\", line 250, in fit\n",
      "    loss.backward()\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/torch/tensor.py\", line 185, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 127, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/posixpath.py\", line 428, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/posixpath.py\", line 81, in join\n",
      "    sep = _get_sep(a)\n",
      "  File \"/home/ec2-user/SageMaker/.persisted_conda/aipt/lib/python3.6/posixpath.py\", line 42, in _get_sep\n",
      "    if isinstance(path, bytes):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-8955fa4298b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PCA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/AIPT-0.0.1-py3.6.egg/AIPT/Models/Beshnova2020/CNN.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, test_loader)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/aipt/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "print('PCA')\n",
    "pca_model.fit(train_loader, test_loader=test_loader)\n",
    "print('\\n\\n\\n')\n",
    "print('GENERAL')\n",
    "general_model.fit(train_loader, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pca_model.net_init()\n",
    "pca_model.load_best()\n",
    "general_model.net_init()\n",
    "general_model.load_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figure_dir = os.path.join(model_dir_abs, 'figures')\n",
    "figure_path = os.path.join(figure_dir, 'memory_naive_roc_train.png')\n",
    "\n",
    "pca_output, pca_labels, pca_loss = pca_model.predict(train_loader)\n",
    "print('PCA')\n",
    "print('total loss: ', pca_loss.item())\n",
    "print('average loss: ', pca_loss.item()/len(train_loader))\n",
    "pca_model.evaluate(pca_output, pca_labels)\n",
    "\n",
    "print()\n",
    "\n",
    "general_output, general_labels, general_loss = general_model.predict(train_loader)\n",
    "print('General')\n",
    "print('total loss: ', general_loss.item())\n",
    "print('average loss: ', general_loss.item()/len(train_loader))\n",
    "general_model.evaluate(general_output, general_labels)\n",
    "plot_roc_curves(\n",
    "    [pca_output[:, 1], general_output[:, 1]],\n",
    "    [pca_labels, general_labels],\n",
    "    [\"PCA Embedding\", \"General Embedding\"],\n",
    "    title=\"Memory vs. Naive B-cell Classification (Train)\",\n",
    "    save_path=figure_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figure_dir = os.path.join(model_dir_abs, 'figures')\n",
    "figure_path = os.path.join(figure_dir, 'memory_naive_roc_test.png')\n",
    "\n",
    "pca_output, pca_labels, pca_loss = pca_model.predict(test_loader)\n",
    "print('PCA')\n",
    "print('total loss: ', pca_loss.item())\n",
    "print('average loss: ', pca_loss.item()/len(train_loader))\n",
    "pca_model.evaluate(pca_output, pca_labels)\n",
    "\n",
    "print()\n",
    "\n",
    "general_output, general_labels, general_loss = general_model.predict(test_loader)\n",
    "print('General')\n",
    "print('total loss: ', general_loss.item())\n",
    "print('average loss: ', general_loss.item()/len(train_loader))\n",
    "general_model.evaluate(general_output, general_labels)\n",
    "plot_roc_curves(\n",
    "    [pca_output[:, 1], general_output[:, 1]],\n",
    "    [pca_labels, general_labels],\n",
    "    [\"PCA Embedding\", \"General Embedding\"],\n",
    "    title=\"Memory vs. Naive B-cell Classification (Test)\",\n",
    "    save_path=figure_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Effect of Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df.iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "aipt_reload(AIPT.Utils.plotting)\n",
    "from AIPT.Utils.plotting import roc_from_models\n",
    "\n",
    "models = {}\n",
    "test_loaders = {}\n",
    "length_dir = os.path.join(model_dir_abs, \"results\", \"length\")\n",
    "for length in range(12, 17):\n",
    "    print(length)\n",
    "    para_dict = para_dict.copy()\n",
    "    para_dict[\"seq_len\"] = length\n",
    "    data = load_data(index_df, seq_len=length)\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    _, test_loader = get_train_test_loaders(data)\n",
    "    test_loaders[str(length)] = test_loader\n",
    "    embedding_type = \"pca\"\n",
    "    model_getter = get_pca_model\n",
    "    model_weights_path = os.path.join(\n",
    "        length_dir, str(length), f\"{embedding_type}_100\", \"model\", \"best\"\n",
    "    )\n",
    "    model = model_getter(para_dict)\n",
    "    model.net_init()\n",
    "    model.load_state_dict(torch.load(model_weights_path))\n",
    "    models[str(length)] = model\n",
    "save_path = os.path.join(length_dir, f\"{embedding_type}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in test_loaders['12']:\n",
    "#     print(x)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_from_models(\n",
    "    models, test_loaders, title=f\"Effect of CDR3 Length\", save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on DeepCAT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aipt_reload(AIPT.Models.Beshnova2020.CNN)\n",
    "aipt_reload(AIPT.Utils.logging)\n",
    "aipt_reload(AIPT.Utils.plotting)\n",
    "from AIPT.Models.Beshnova2020.CNN import CNN\n",
    "import AIPT.Models.Beshnova2020.pca_embedding as pca_embedding\n",
    "from AIPT.Utils.logging import today, current_time\n",
    "from AIPT.Utils.plotting import plot_roc_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_root_dir = 's3://gv20interns/roger/logs/tensorboard'\n",
    "run_name = 'deepcat_test'\n",
    "timezone = 'EST'\n",
    "\n",
    "para_dict = {\n",
    "#     'seq_len': 12,\n",
    "    'embedding_dim': 15, # paper uses dim 15 PCA features\n",
    "#     'epoch': 1000,\n",
    "    'classes': ['normal', 'tumor'],\n",
    "    'learning_rate': 10**-3,\n",
    "    'run_name': run_name,\n",
    "    'log_dir': os.path.join(log_root_dir, today(tz=timezone), run_name, current_time(tz=timezone)),\n",
    "    'work_path': os.path.join(model_dir_abs, 'work/DeepCAT')\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dir = os.path.join(model_dir_abs, 'data')\n",
    "fnormal = os.path.join(data_dir, 'NormalCDR3.txt')\n",
    "ftumor = os.path.join(data_dir, 'TumorCDR3.txt')\n",
    "\n",
    "def load_deepcat_data(ftumor, fnormal, seq_len = 12):\n",
    "    tumorCDR3s=[]\n",
    "    g=open(ftumor)\n",
    "    for ll in g.readlines():\n",
    "        rr=ll.strip()\n",
    "        if not rr.startswith('C') or not rr.endswith('F'):\n",
    "            print(\"Non-standard CDR3s. Skipping.\")\n",
    "            continue\n",
    "        if len(rr) != seq_len:\n",
    "            continue\n",
    "        tumorCDR3s.append(rr)\n",
    "    normalCDR3s=[]\n",
    "    g=open(fnormal)\n",
    "    for ll in g.readlines():\n",
    "        rr=ll.strip()\n",
    "        if not rr.startswith('C') or not rr.endswith('F'):\n",
    "            print(\"Non-standard CDR3s. Skipping.\")\n",
    "            continue\n",
    "        if len(rr) != seq_len:\n",
    "            continue\n",
    "        normalCDR3s.append(rr)\n",
    "        \n",
    "    normal_df = pd.DataFrame(normalCDR3s)\n",
    "    normal_df.columns = ['CDR3_aa']\n",
    "    normal_df['label'] = 0\n",
    "\n",
    "    tumor_df = pd.DataFrame(tumorCDR3s)\n",
    "    tumor_df.columns = ['CDR3_aa']\n",
    "    tumor_df['label'] = 1\n",
    "\n",
    "    data_df = pd.concat([normal_df, tumor_df])\n",
    "    return data_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = range(12, 17)\n",
    "accs = {}\n",
    "for seq_length in seq_lengths:\n",
    "    \n",
    "    dc_para_dict = para_dict.copy()\n",
    "    dc_para_dict['seq_len'] = seq_length\n",
    "    \n",
    "    data_df = load_deepcat_data(ftumor, fnormal, seq_len=seq_length)\n",
    "    print(data_df)\n",
    "    dc_train_loader = get_data_loader(data_df)\n",
    "    \n",
    "    num_batches = len(dc_train_loader)\n",
    "    dc_steps = 40000\n",
    "    dc_para_dict['epoch'] = dc_steps//num_batches\n",
    "    dc_para_dict['model_name'] = f'deepcat_torch_seqlen{seq_length}'\n",
    "    pca_embedding_fn = pca_embedding.embedding_fn(20, dc_para_dict['embedding_dim'])\n",
    "    dc_model = CNN(dc_para_dict, pca_embedding_fn)\n",
    "    \n",
    "    results = dc_model.fit(dc_train_loader)\n",
    "    accs[seq_length] = results['train']['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pt_results = accs\n",
    "tf_results = {\n",
    "    12: 0.8610463741917541,\n",
    "    13: 0.8308455045175356,\n",
    "    14: 0.7865194836315643,\n",
    "    15: 0.82875444017,\n",
    "    16: 0.85230856924342,\n",
    "}\n",
    "def get_results_df(results_dict, framework):\n",
    "    lengths = results_dict.keys()\n",
    "    accs = results_dict.values()\n",
    "    df = pd.DataFrame.from_dict({'seq_len': lengths, 'acc': accs})\n",
    "    df['Framework'] = framework\n",
    "    return df\n",
    "\n",
    "\n",
    "df_path = os.path.join(model_dir_abs, 'comparison.csv')\n",
    "if os.path.isfile(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "else:\n",
    "    pt_df = get_results_df(pt_results, framework='PyTorch')\n",
    "    tf_df = get_results_df(tf_results, framework='TensorFlow')\n",
    "    df = pd.concat([pt_df, tf_df])\n",
    "    df.to_csv(df_path)\n",
    "print(df)\n",
    "\n",
    "sns.color_palette('bright')\n",
    "fig = sns.barplot(data=df, x='seq_len', y='acc', hue='Framework')\n",
    "fig.set(xlabel='Sequence Length', ylabel='Accuracy', title='DeepCAT Reimplementation Accuracies')\n",
    "fig_path = os.path.join(model_dir_abs, 'comparision.png')\n",
    "fig.figure.savefig(fig_path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH ec2-user@0.tcp.ngrok.io:10507 roger-aipt2-2020-10-25-1603693660",
   "language": "",
   "name": "rik_ssh_ec2_user_0_tcp_ngrok_io_10507_rogeraipt2202010251603693660"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
